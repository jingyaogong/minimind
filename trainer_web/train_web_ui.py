import os
import sys
import subprocess
import threading
import json
import socket
import atexit
import signal
from flask import Flask, render_template, request, jsonify, redirect, url_for
import time
import psutil

# å°è¯•å¯¼å…¥torchæ¥æ£€æµ‹GPU
try:
    import torch
    HAS_TORCH = True
    # æ£€æµ‹å¯ç”¨çš„GPUæ•°é‡å’Œè®¾å¤‡ä¿¡æ¯
    if torch.cuda.is_available():
        GPU_COUNT = torch.cuda.device_count()
        # è·å–GPUè®¾å¤‡åç§°
        GPU_NAMES = [torch.cuda.get_device_name(i) for i in range(GPU_COUNT)]
    else:
        GPU_COUNT = 0
        GPU_NAMES = []
except ImportError:
    HAS_TORCH = False
    GPU_COUNT = 0
    GPU_NAMES = []

# è®­ç»ƒæ–¹å¼æ”¯æŒæ£€æµ‹
def get_supported_training_methods():
    """è·å–å½“å‰ç¯å¢ƒæ”¯æŒçš„è®­ç»ƒæ–¹æ³•"""
    methods = {
        'pretrain': True,  # é¢„è®­ç»ƒæ€»æ˜¯æ”¯æŒ
        'sft': True,       # SFTæ€»æ˜¯æ”¯æŒ
        'lora': True,      # LoRAæ€»æ˜¯æ”¯æŒ
        'dpo': True,       # DPOæ€»æ˜¯æ”¯æŒ
        'multi_gpu': HAS_TORCH and GPU_COUNT > 1  # å¤šGPUè®­ç»ƒéœ€è¦PyTorchå’Œå¤šä¸ªGPU
    }
    return methods

# è·å–å½“å‰ç¯å¢ƒæ”¯æŒçš„è®­ç»ƒæ–¹æ³•
SUPPORTED_METHODS = get_supported_training_methods()

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

app = Flask(__name__, template_folder='templates', static_folder='static')

# å­˜å‚¨è®­ç»ƒè¿›ç¨‹çš„ä¿¡æ¯
training_processes = {}

# è¿›ç¨‹ä¿¡æ¯æŒä¹…åŒ–æ–‡ä»¶
PROCESSES_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'training_processes.json')

# PIDæ–‡ä»¶
PID_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'train_web_ui.pid')

# å¯åŠ¨è®­ç»ƒè¿›ç¨‹
def start_training_process(train_type, params):
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # ä½¿ç”¨è¯¦ç»†çš„æ—¶é—´æˆ³ä½œä¸ºè¿›ç¨‹IDå’Œæ—¥å¿—æ–‡ä»¶å
    process_id = time.strftime('%Y%m%d_%H%M%S')
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    log_file = os.path.join(log_dir, f"train_{train_type}_{process_id}.log")
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(log_dir, exist_ok=True)
    
    # è·å–GPUæ•°é‡å‚æ•°ï¼Œå¦‚æœå­˜åœ¨ä¸”å¤§äº1ï¼Œåˆ™ä½¿ç”¨torchrunå¯åŠ¨å¤šå¡è®­ç»ƒ
    gpu_num = int(params.get('gpu_num', 0)) if 'gpu_num' in params else 0
    use_torchrun = HAS_TORCH and GPU_COUNT > 0 and gpu_num > 1
    
    # æ„å»ºå‘½ä»¤
    if train_type == 'pretrain':
        script_path = '../trainer/train_pretrain.py'
        if use_torchrun:
            cmd = ['torchrun', '--nproc_per_node', str(gpu_num), script_path]
        else:
            cmd = [sys.executable, script_path]
        if 'save_weight' in params:
            cmd.extend(['--save_weight', params['save_weight']])
    elif train_type == 'sft':
        script_path = '../trainer/train_full_sft.py'
        if use_torchrun:
            cmd = ['torchrun', '--nproc_per_node', str(gpu_num), script_path]
        else:
            cmd = [sys.executable, script_path]
        if 'save_weight' in params:
            cmd.extend(['--save_weight', params['save_weight']])
    elif train_type == 'lora':
        script_path = '../trainer/train_lora.py'
        if use_torchrun:
            cmd = ['torchrun', '--nproc_per_node', str(gpu_num), script_path]
        else:
            cmd = [sys.executable, script_path]
        if 'lora_name' in params:
            cmd.extend(['--lora_name', params['lora_name']])
    elif train_type == 'dpo':
        script_path = '../trainer/train_dpo.py'
        if use_torchrun:
            cmd = ['torchrun', '--nproc_per_node', str(gpu_num), script_path]
        else:
            cmd = [sys.executable, script_path]
        # æ·»åŠ DPOç‰¹å®šå‚æ•°
        if 'beta' in params and params['beta']:
            cmd.extend(['--beta', params['beta']])
        if 'accumulation_steps' in params and params['accumulation_steps']:
            cmd.extend(['--accumulation_steps', params['accumulation_steps']])
        if 'grad_clip' in params and params['grad_clip']:
            cmd.extend(['--grad_clip', params['grad_clip']])
    elif train_type == 'ppo':
        script_path = '../trainer/train_ppo.py'
        if use_torchrun:
            cmd = ['torchrun', '--nproc_per_node', str(gpu_num), script_path]
        else:
            cmd = [sys.executable, script_path]
        # æ·»åŠ PPOç‰¹å®šå‚æ•°
        if 'clip_epsilon' in params and params['clip_epsilon']:
            cmd.extend(['--clip_epsilon', params['clip_epsilon']])
        if 'vf_coef' in params and params['vf_coef']:
            cmd.extend(['--vf_coef', params['vf_coef']])
        if 'kl_coef' in params and params['kl_coef']:
            cmd.extend(['--kl_coef', params['kl_coef']])
        if 'reasoning' in params and params['reasoning']:
            cmd.extend(['--reasoning', params['reasoning']])
        if 'update_old_actor_freq' in params and params['update_old_actor_freq']:
            cmd.extend(['--update_old_actor_freq', params['update_old_actor_freq']])
        if 'reward_model_path' in params and params['reward_model_path']:
            cmd.extend(['--reward_model_path', params['reward_model_path']])
    else:
        return None
    
    # æ·»åŠ é€šç”¨å‚æ•°
    for key, value in params.items():
        # è·³è¿‡ç‰¹æ®Šå‚æ•°å’ŒDPOã€PPOç‰¹æœ‰å‚æ•°ï¼Œä»¥åŠgpu_numå‚æ•°ï¼ˆå› ä¸ºå·²ç»åœ¨torchrunå‘½ä»¤ä¸­ä½¿ç”¨ï¼‰
        # å¯¹äºPPOè®­ç»ƒï¼Œè·³è¿‡--from_weightå‚æ•°
        if key in ['train_type', 'save_weight', 'lora_name', 'train_monitor', 'beta', 'accumulation_steps', 'grad_clip', 'gpu_num', 'clip_epsilon', 'vf_coef', 'kl_coef', 'reasoning', 'update_old_actor_freq', 'reward_model_path'] or (train_type == 'ppo' and key == 'from_weight'):
            continue
        # å¯¹äºfrom_resumeå‚æ•°ï¼Œéœ€è¦æ­£ç¡®ä¼ é€’å‚æ•°å€¼
        elif key == 'from_resume':
            # ç¡®ä¿ä¼ é€’å‚æ•°åå’Œå‚æ•°å€¼
            cmd.extend([f'--{key}', str(value)])
        else:
            # ç¡®ä¿log_intervalå’Œsave_intervalå‚æ•°æ­£ç¡®ä¼ é€’
            cmd.extend([f'--{key}', str(value)])
    
    # å•ç‹¬å¤„ç†è®­ç»ƒç›‘æ§å‚æ•°ï¼Œç¡®ä¿å®ƒä¸ä¼šè¢«é”™è¯¯åœ°æ·»åŠ å€¼
    if 'train_monitor' in params:
        if params['train_monitor'] == 'wandb' or params['train_monitor'] == 'swanlab':
            cmd.append('--use_wandb')  # å¯¹äºwandbå’Œswanlabï¼Œåªæ·»åŠ æ ‡å¿—ï¼Œä¸æ·»åŠ å€¼
            if params['train_monitor'] == 'wandb':
                cmd.extend(['--wandb_project', 'minimind_training'])
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    with open(log_file, 'w') as f:
        f.write(f"å¼€å§‹è®­ç»ƒ {train_type} è¿›ç¨‹\n")
        f.write(f"å‘½ä»¤: {' '.join(cmd)}\n\n")
    
    # å¯åŠ¨è¿›ç¨‹
    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        cwd=os.path.dirname(os.path.abspath(__file__))
    )
    
    # å­˜å‚¨è¿›ç¨‹ä¿¡æ¯
    training_processes[process_id] = {
        'process': process,
        'train_type': train_type,
        'log_file': log_file,
        'start_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'running': True,
        'error': False,
        'train_monitor': params.get('train_monitor', 'none'),  # ä¿å­˜è®­ç»ƒç›‘æ§è®¾ç½®
        'swanlab_url': None,
        'next_line_is_swanlab_url': False
    }
    
    # å¼€å§‹è¯»å–è¾“å‡º
    def read_output():
        try:
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯swanlabé“¾æ¥çš„è¡Œ
                    output_stripped = output.strip()
                    if training_processes[process_id]['next_line_is_swanlab_url']:
                        # ä¿å­˜swanlabé“¾æ¥
                        training_processes[process_id]['swanlab_url'] = output_stripped
                        training_processes[process_id]['next_line_is_swanlab_url'] = False
                    elif 'swanlab: ğŸš€ View run at' in output_stripped:
                        # æ ‡è®°ä¸‹ä¸€è¡Œæ˜¯swanlabé“¾æ¥
                        training_processes[process_id]['next_line_is_swanlab_url'] = True
                    
                    with open(log_file, 'a') as f:
                        f.write(output)
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦æˆåŠŸç»“æŸ
            if process.returncode != 0:
                training_processes[process_id]['error'] = True
        finally:
            training_processes[process_id]['running'] = False
    
    # å¯åŠ¨çº¿ç¨‹è¯»å–è¾“å‡º
    threading.Thread(target=read_output, daemon=True).start()
    
    return process_id

# Flaskè·¯ç”±
@app.route('/')
def index():
    # ä¼ é€’GPUä¿¡æ¯åˆ°å‰ç«¯
    return render_template('index.html', has_gpu=HAS_TORCH and GPU_COUNT > 0, gpu_count=GPU_COUNT)

@app.route('/train', methods=['POST'])
def train():
    data = request.json
    train_type = data.get('train_type')
    
    # ç§»é™¤ä¸ç›¸å…³çš„å‚æ•°
    params = data.copy()
    
    # å¤„ç†å¤é€‰æ¡†å‚æ•°
    if 'from_resume' not in params:
        params['from_resume'] = '0'
    
    # å¯åŠ¨è®­ç»ƒè¿›ç¨‹
    process_id = start_training_process(train_type, params)
    
    if process_id:
        return jsonify({'success': True, 'process_id': process_id})
    else:
        return jsonify({'success': False, 'error': 'æ— æ•ˆçš„è®­ç»ƒç±»å‹'})

@app.route('/processes')
def processes():
    result = []
    for process_id, info in training_processes.items():
        # ç¡®å®šçŠ¶æ€
        status = 'è¿è¡Œä¸­' if info['running'] else \
                'æ‰‹åŠ¨åœæ­¢' if 'manually_stopped' in info and info['manually_stopped'] else \
                'å‡ºé”™' if info['error'] else 'å·²å®Œæˆ'
                
        result.append({
            'id': process_id,
            'train_type': info['train_type'],
            'start_time': info['start_time'],
            'running': info['running'],
            'error': info['error'],
            'status': status,
            'train_monitor': info.get('train_monitor', 'none'),  # æ·»åŠ train_monitorå­—æ®µ
            'swanlab_url': info.get('swanlab_url')  # æ·»åŠ swanlab_urlå­—æ®µ
        })
    return jsonify(result)

@app.route('/logs/<process_id>')
def logs(process_id):
    # ç›´æ¥ä»æœ¬åœ°logfileç›®å½•è¯»å–æ—¥å¿—æ–‡ä»¶
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    
    # æŸ¥æ‰¾åŒ¹é…çš„æ—¥å¿—æ–‡ä»¶
    log_file = None
    if os.path.exists(log_dir):
        for filename in os.listdir(log_dir):
            if filename.endswith(f'{process_id}.log'):
                log_file = os.path.join(log_dir, filename)
                break
    
    if not log_file or not os.path.exists(log_file):
        return 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤'
    
    try:
        # ä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼è¯»å–ï¼Œç„¶åå°è¯•è§£ç ä»¥å¤„ç†ä¸åŒç¼–ç çš„æ—¥å¿—æ–‡ä»¶
        def read_log_file_robust(file_path):
            # å°è¯•å¤šç§ç¼–ç æ–¹å¼è¯»å–æ–‡ä»¶
            encodings = ['utf-8', 'latin-1', 'gbk', 'gb2312']
            for encoding in encodings:
                try:
                    with open(file_path, 'r', encoding=encoding) as f:
                        return f.read(), encoding
                except UnicodeDecodeError:
                    continue
            # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼è¯»å–å¹¶æ›¿æ¢ä¸å¯è§£ç çš„å­—ç¬¦
            with open(file_path, 'rb') as f:
                content = f.read()
            return content.decode('utf-8', errors='replace'), 'binary_decoded'
        
        # ä½¿ç”¨é«˜æ•ˆçš„æ–¹æ³•è¯»å–æ–‡ä»¶çš„æœ€å200è¡Œï¼Œç¡®ä¿ä»¥å®Œæ•´è¡Œä¸ºå•ä½
        last_200_lines = []
        
        # å…ˆå°è¯•ä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼è¯»å–æ–‡ä»¶æœ«å°¾çš„éƒ¨åˆ†
        with open(log_file, 'rb') as f:
            # å°è¯•ç›´æ¥å®šä½åˆ°æ–‡ä»¶æœ«å°¾ï¼Œç„¶åå‘å‰è¯»å–
            f.seek(0, os.SEEK_END)
            file_size = f.tell()
            
            # è®¡ç®—éœ€è¦è¯»å–çš„å—æ•°
            position = file_size
            blocks = []
            block_size = 8192  # 8KB blocks
            
            # ç¡®ä¿æˆ‘ä»¬æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥å¤„ç†å®Œæ•´è¡Œ
            found_complete_lines = False
            while position > 0 and not found_complete_lines:
                # åé€€ä¸€ä¸ªå—çš„ä½ç½®
                position -= block_size
                if position < 0:
                    position = 0
                
                # ç§»åŠ¨åˆ°è®¡ç®—çš„ä½ç½®
                f.seek(position)
                
                # è¯»å–è¿™ä¸ªå—
                block = f.read(block_size)
                blocks.append(block)
                
                # å¦‚æœå·²ç»æ”¶é›†äº†è¶³å¤Ÿçš„æ•°æ®ï¼Œå°è¯•è§£ç å¹¶æ£€æŸ¥è¡Œæ•°
                combined_binary = b''.join(blocks)
                # å°è¯•è§£ç ï¼Œä½¿ç”¨errors='replace'å¤„ç†æ— æ³•è§£ç çš„å­—ç¬¦
                try:
                    combined_text = combined_binary.decode('utf-8', errors='replace')
                except:
                    combined_text = combined_binary.decode('latin-1')
                
                lines = combined_text.splitlines(True)  # ä½¿ç”¨Trueä¿ç•™æ¢è¡Œç¬¦
                
                # ç¡®ä¿æˆ‘ä»¬ä¸è¿”å›ä¸å®Œæ•´çš„ç¬¬ä¸€è¡Œ
                if len(lines) > 0:
                    # å¦‚æœæœ‰è¶³å¤Ÿçš„è¡Œï¼Œç¡®ä¿æˆ‘ä»¬ä»ä¸€ä¸ªå®Œæ•´è¡Œå¼€å§‹
                    if len(lines) > 1:
                        # è·³è¿‡å¯èƒ½ä¸å®Œæ•´çš„ç¬¬ä¸€è¡Œ
                        last_200_lines = lines[1:]
                    else:
                        last_200_lines = lines
                    
                    # å¦‚æœæˆ‘ä»¬æœ‰è¶³å¤Ÿçš„è¡Œï¼Œåœæ­¢è¯»å–
                    if len(last_200_lines) >= 200:
                        # è·å–æœ€å200è¡Œ
                        last_200_lines = last_200_lines[-200:]
                        found_complete_lines = True
            
            # å¦‚æœæ–‡ä»¶å†…å®¹ä¸è¶³200è¡Œï¼Œæˆ–è€…ä¸Šé¢çš„æ–¹æ³•æ²¡æœ‰æ”¶é›†åˆ°è¶³å¤Ÿçš„è¡Œ
            if len(last_200_lines) < 200:
                # é‡æ–°è¯»å–æ•´ä¸ªæ–‡ä»¶ï¼ˆå¯¹äºå°æ–‡ä»¶ï¼‰
                content, encoding = read_log_file_robust(log_file)
                all_lines = content.splitlines(True)  # ä½¿ç”¨Trueä¿ç•™æ¢è¡Œç¬¦
                last_200_lines = all_lines[-200:] if len(all_lines) > 200 else all_lines
        
        return ''.join(last_200_lines)
    except Exception as e:
        return f'è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}'

@app.route('/logfiles')
def get_logfiles():
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    
    logfiles = []
    if os.path.exists(log_dir):
        for filename in os.listdir(log_dir):
            if filename.endswith('.log') and filename.startswith('train_'):
                file_path = os.path.join(log_dir, filename)
                try:
                    modified_time = os.path.getmtime(file_path)
                    formatted_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modified_time))
                    logfiles.append({
                        'filename': filename,
                        'modified_time': formatted_time,
                        'size': os.path.getsize(file_path)
                    })
                except Exception as e:
                    continue
    # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
    logfiles.sort(key=lambda x: x['modified_time'], reverse=True)
    return jsonify(logfiles)

@app.route('/logfile-content/<filename>')
def get_logfile_content(filename):
    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åä¸åŒ…å«è·¯å¾„éå†å­—ç¬¦
    if '..' in filename or '/' in filename or '\\' in filename:
        return jsonify({'error': 'Invalid filename'}), 400
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œtrain_web_ui.pyåœ¨scriptsç›®å½•ä¸‹
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    log_file = os.path.join(log_dir, filename)
    
    try:
        # ä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼è¯»å–æ–‡ä»¶ï¼Œå¯ä»¥æ›´å¯é åœ°ä¿ç•™åŸå§‹æ¢è¡Œç¬¦
        with open(log_file, 'rb') as f:
            content_bytes = f.read()
        
        # å°è¯•å¤šç§ç¼–ç æ–¹å¼è§£ç ï¼Œç¡®ä¿æ­£ç¡®å¤„ç†æ¢è¡Œç¬¦
        encodings = ['utf-8', 'latin-1', 'gbk', 'gb2312']
        content = None
        
        for encoding in encodings:
            try:
                # è§£ç æ–‡ä»¶å†…å®¹ï¼Œä¿ç•™åŸå§‹æ¢è¡Œç¬¦
                content = content_bytes.decode(encoding)
                break
            except UnicodeDecodeError:
                continue
        
        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨errors='replace'å‚æ•°å¤„ç†ä¸å¯è§£ç çš„å­—ç¬¦
        if content is None:
            content = content_bytes.decode('utf-8', errors='replace')
        
        # ç¡®ä¿è¿”å›çš„å†…å®¹æ­£ç¡®ä¿ç•™æ‰€æœ‰æ¢è¡Œç¬¦
        return content
    except FileNotFoundError:
        return jsonify({'error': 'Log file not found'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/delete-logfile/<filename>', methods=['DELETE'])
def delete_logfile(filename):
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    
    # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
    if '..' in filename or '/' in filename or '\\' in filename:
        return jsonify({'success': False, 'message': 'éæ³•çš„æ–‡ä»¶å'})
    
    log_file = os.path.join(log_dir, filename)
    if os.path.exists(log_file) and os.path.isfile(log_file):
        try:
            os.remove(log_file)
            return jsonify({'success': True, 'message': 'æ—¥å¿—æ–‡ä»¶åˆ é™¤æˆåŠŸ'})
        except Exception as e:
            print(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
            return jsonify({'success': False, 'message': f'åˆ é™¤å¤±è´¥: {str(e)}'})
    return jsonify({'success': False, 'message': 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨'})


@app.route('/stop/<process_id>', methods=['POST'])
def stop(process_id):
    if process_id in training_processes and training_processes[process_id]['running']:
        process = training_processes[process_id]['process']
        # åœ¨Windowsä¸Šä½¿ç”¨terminateï¼Œåœ¨Unixä¸Šå°è¯•ä¼˜é›…ç»ˆæ­¢
        try:
            process.terminate()
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            process.wait(timeout=5)
            # æ ‡è®°ä¸ºæ‰‹åŠ¨åœæ­¢
            training_processes[process_id]['running'] = False
            training_processes[process_id]['manually_stopped'] = True
        except subprocess.TimeoutExpired:
            # å¦‚æœè¶…æ—¶ï¼Œå¼ºåˆ¶æ€æ­»
            process.kill()
            # æ ‡è®°ä¸ºæ‰‹åŠ¨åœæ­¢
            training_processes[process_id]['running'] = False
            training_processes[process_id]['manually_stopped'] = True
        return jsonify({'success': True})
    return jsonify({'success': False})

@app.route('/delete/<process_id>', methods=['POST'])
def delete(process_id):
    if process_id in training_processes:
        # ç¡®ä¿è¿›ç¨‹å·²ç»åœæ­¢
        if training_processes[process_id]['running']:
            # å¦‚æœè¿›ç¨‹è¿˜åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢å®ƒ
            try:
                process = training_processes[process_id]['process']
                process.terminate()
                try:
                    process.wait(timeout=3)
                except subprocess.TimeoutExpired:
                    process.kill()
            except Exception as e:
                print(f"åœæ­¢è¿›ç¨‹å¤±è´¥: {str(e)}")
        
        # ä»è¿›ç¨‹å­—å…¸ä¸­åˆ é™¤
        del training_processes[process_id]
        
        # å¯é€‰ï¼šåˆ é™¤å¯¹åº”çš„æ—¥å¿—æ–‡ä»¶
        try:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            log_dir = os.path.join(script_dir, '../logfile')
            log_dir = os.path.abspath(log_dir)
            
            if os.path.exists(log_dir):
                for filename in os.listdir(log_dir):
                    if filename.endswith(f'{process_id}.log'):
                        os.remove(os.path.join(log_dir, filename))
        except Exception as e:
            print(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        return jsonify({'success': True})
    return jsonify({'success': False})

def find_available_port(start_port=5000, max_attempts=100):
    """æŸ¥æ‰¾å¯ç”¨çš„ç«¯å£å·
    
    Args:
        start_port: èµ·å§‹ç«¯å£å·
        max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°
        
    Returns:
        å¯ç”¨çš„ç«¯å£å·ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
    """
    for port in range(start_port, start_port + max_attempts):
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        result = sock.connect_ex(('localhost', port))
        sock.close()
        if result != 0:  # ç«¯å£å¯ç”¨
            return port
    return None

def save_processes_info():
    """ä¿å­˜è®­ç»ƒè¿›ç¨‹ä¿¡æ¯åˆ°æ–‡ä»¶"""
    try:
        # åˆ›å»ºä¸€ä¸ªä¸åŒ…å«è¿›ç¨‹å¯¹è±¡çš„å¯åºåˆ—åŒ–ç‰ˆæœ¬
        serializable_processes = {}
        for pid, info in training_processes.items():
            serializable_processes[pid] = {
                'pid': info.get('pid', info.get('process').pid) if isinstance(info.get('process'), subprocess.Popen) else info.get('pid'),
                'train_type': info['train_type'],
                'log_file': info['log_file'],
                'start_time': info['start_time'],
                'running': info['running'],
                'error': info.get('error', False),
                'manually_stopped': info.get('manually_stopped', False),
                'train_monitor': info.get('train_monitor', 'none'),  # ä¿å­˜train_monitor
                'swanlab_url': info.get('swanlab_url')  # ä¿å­˜swanlab_url
            }
        
        with open(PROCESSES_FILE, 'w', encoding='utf-8') as f:
            json.dump(serializable_processes, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ä¿å­˜è¿›ç¨‹ä¿¡æ¯å¤±è´¥: {str(e)}")

def load_processes_info():
    """ä»æ–‡ä»¶åŠ è½½è®­ç»ƒè¿›ç¨‹ä¿¡æ¯"""
    global training_processes
    try:
        if os.path.exists(PROCESSES_FILE):
            with open(PROCESSES_FILE, 'r', encoding='utf-8') as f:
                loaded_processes = json.load(f)
            
            # æ£€æŸ¥æ¯ä¸ªè¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
            for pid, info in loaded_processes.items():
                # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„å­—æ®µéƒ½å­˜åœ¨
                if 'swanlab_url' not in info:
                    info['swanlab_url'] = None
                if 'manually_stopped' not in info:
                    info['manually_stopped'] = False
                if 'error' not in info:
                    info['error'] = False
                if 'train_monitor' not in info:
                    info['train_monitor'] = 'none'
                
                if info['running']:
                    try:
                        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                        proc = psutil.Process(info['pid'])
                        if proc.is_running() and proc.status() != 'zombie':
                            # è¿›ç¨‹ä»åœ¨è¿è¡Œï¼Œæ¢å¤ä¿¡æ¯
                            training_processes[pid] = info
                        else:
                            # è¿›ç¨‹å·²åœæ­¢
                            info['running'] = False
                            # å¦‚æœè¿›ç¨‹æœªè¢«æ˜ç¡®æ ‡è®°ä¸ºå®Œæˆæˆ–å‡ºé”™ï¼Œåˆ™é»˜è®¤ä¸ºæ‰‹åŠ¨åœæ­¢
                            if not info['error']:
                                info['manually_stopped'] = True
                            training_processes[pid] = info
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        # è¿›ç¨‹ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®
                        info['running'] = False
                        # å¦‚æœè¿›ç¨‹æœªè¢«æ˜ç¡®æ ‡è®°ä¸ºå®Œæˆæˆ–å‡ºé”™ï¼Œåˆ™é»˜è®¤ä¸ºæ‰‹åŠ¨åœæ­¢
                        if not info['error']:
                            info['manually_stopped'] = True
                        training_processes[pid] = info
                else:
                    # è¿›ç¨‹å·²åœæ­¢ï¼Œç›´æ¥æ¢å¤
                    training_processes[pid] = info
    except Exception as e:
        print(f"åŠ è½½è¿›ç¨‹ä¿¡æ¯å¤±è´¥: {str(e)}")

def handle_exit(signum, frame):
    """å¤„ç†ç¨‹åºé€€å‡ºä¿¡å·ï¼Œä¿å­˜è¿›ç¨‹ä¿¡æ¯"""
    print("æ­£åœ¨ä¿å­˜è¿›ç¨‹ä¿¡æ¯...")
    save_processes_info()
    # åˆ é™¤PIDæ–‡ä»¶
    if os.path.exists(PID_FILE):
        try:
            os.remove(PID_FILE)
        except:
            pass
    sys.exit(0)

# æ³¨å†Œé€€å‡ºå¤„ç†å™¨
signal.signal(signal.SIGINT, handle_exit)  # Ctrl+C
if hasattr(signal, 'SIGTERM'):
    signal.signal(signal.SIGTERM, handle_exit)  # ç»ˆæ­¢ä¿¡å·

# æ³¨å†Œç¨‹åºé€€å‡ºæ—¶çš„å¤„ç†å‡½æ•°
atexit.register(save_processes_info)

if __name__ == '__main__':
    # åŠ è½½å·²ä¿å­˜çš„è¿›ç¨‹ä¿¡æ¯
    load_processes_info()
    
    # åˆ›å»ºPIDæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯†webè¿›ç¨‹
    with open(PID_FILE, 'w') as f:
        f.write(str(os.getpid()))
    
    # å°è¯•ä½¿ç”¨é»˜è®¤ç«¯å£5000ï¼Œå¦‚æœè¢«å ç”¨åˆ™è‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£
    port = find_available_port(5000)
    if port is not None:
        print(f"å¯åŠ¨FlaskæœåŠ¡å™¨åœ¨ http://0.0.0.0:{port}")
        print(f"ä½¿ç”¨nohupå¯åŠ¨å¯ä¿æŒæœåŠ¡æŒç»­è¿è¡Œ: nohup python -u scripts/train_web_ui.py &")
        # ä½¿ç”¨0.0.0.0ä½œä¸ºhostä»¥å…¼å®¹VSCodeçš„ç«¯å£è½¬å‘åŠŸèƒ½
        app.run(host='0.0.0.0', port=port, debug=False)  # ç”Ÿäº§ç¯å¢ƒå…³é—­debug
    else:
        print("æ— æ³•æ‰¾åˆ°å¯ç”¨çš„ç«¯å£ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿç«¯å£å ç”¨æƒ…å†µ")
        # åˆ é™¤PIDæ–‡ä»¶
        if os.path.exists(PID_FILE):
            try:
                os.remove(PID_FILE)
            except:
                pass
        sys.exit(1)