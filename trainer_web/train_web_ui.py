import os
import sys
import subprocess
import threading
import json
import socket
import atexit
import signal
import re
from flask import Flask, render_template, request, jsonify, redirect, url_for
from flask import g
import time
import psutil
import glob
import pathlib

# å°è¯•å¯¼å…¥torchæ¥æ£€æµ‹GPU
try:
    import torch
    HAS_TORCH = True
    # æ£€æµ‹å¯ç”¨çš„GPUæ•°é‡å’Œè®¾å¤‡ä¿¡æ¯
    if torch.cuda.is_available():
        GPU_COUNT = torch.cuda.device_count()
        # è·å–GPUè®¾å¤‡åç§°
        GPU_NAMES = [torch.cuda.get_device_name(i) for i in range(GPU_COUNT)]
    else:
        GPU_COUNT = 0
        GPU_NAMES = []
except ImportError:
    HAS_TORCH = False
    GPU_COUNT = 0
    GPU_NAMES = []

def calculate_training_progress(process_id, process_info):
    """
    è®¡ç®—è®­ç»ƒè¿›åº¦ä¿¡æ¯
    ä»æ—¥å¿—æ–‡ä»¶ä¸­æå–è®­ç»ƒè¿›åº¦ã€lossã€epochç­‰ä¿¡æ¯
    """
    progress = {
        'percentage': 0,
        'current_epoch': 0,
        'total_epochs': 0,
        'remaining_time': 'è®¡ç®—ä¸­...',
        'current_loss': None,
        'current_lr': None
    }
    
    # å¦‚æœè¿›ç¨‹ä¸åœ¨è¿è¡Œï¼Œè¿”å›ç©ºè¿›åº¦
    if not process_info.get('running', False):
        return progress
    
    try:
        # è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        log_dir = os.path.join(script_dir, '../logfile')
        log_dir = os.path.abspath(log_dir)
        
        log_file = None
        if os.path.exists(log_dir):
            for filename in os.listdir(log_dir):
                if filename.endswith(f'{process_id}.log'):
                    log_file = os.path.join(log_dir, filename)
                    break
        
        if not log_file or not os.path.exists(log_file):
            return progress
        
        # è¯»å–æ—¥å¿—æ–‡ä»¶çš„æœ€å1000è¡Œ
        def read_last_lines(file_path, n=1000):
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    # ä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹æ³•è¯»å–æœ€ånè¡Œ
                    lines = []
                    for line in f:
                        lines.append(line.strip())
                        if len(lines) > n:
                            lines.pop(0)
                    return lines
            except Exception:
                return []
        
        lines = read_last_lines(log_file, 1000)
        
        # ä»æ—¥å¿—ä¸­æå–è¿›åº¦ä¿¡æ¯
        current_epoch = 0
        total_epochs = 0
        current_loss = None
        current_lr = None
        
        for line in reversed(lines):  # ä»æœ€æ–°æ—¥å¿—å¼€å§‹
            line = line.strip()
            if not line:
                continue
                
            # æå–epochä¿¡æ¯ - æ”¯æŒå¤šç§æ ¼å¼
            if not total_epochs:
                # æ ¼å¼: epoch 3/10, Epoch 3 of 10, [3/10], ç¬¬3è½®/å…±10è½®
                epoch_patterns = [
                    r'epoch\s+(\d+)\s*/\s*(\d+)',
                    r'Epoch\s+(\d+)\s*of\s*(\d+)',
                    r'\[(\d+)/(\d+)\]',
                    r'epoch\s*[:ï¼š]\s*(\d+)\s*/\s*(\d+)',
                    r'ç¬¬\s*(\d+)\s*è½®\s*/\s*å…±\s*(\d+)\s*è½®'
                ]
                
                for pattern in epoch_patterns:
                    match = re.search(pattern, line, re.IGNORECASE)
                    if match:
                        current_epoch = int(match.group(1))
                        total_epochs = int(match.group(2))
                        break
            
            # æå–lossä¿¡æ¯ - æ”¯æŒå¤šç§æ ¼å¼
            if not current_loss:
                # æ ¼å¼: loss: 4.32, training_loss: 4.32, train_loss: 4.32, Loss: 4.32, è®­ç»ƒæŸå¤±: 4.32
                loss_patterns = [
                    r'loss[\s:=]\s*([\d.]+(?:e[+-]?\d+)?)',           # loss: 4.32
                    r'training_loss[\s:=]\s*([\d.]+(?:e[+-]?\d+)?)',  # training_loss: 4.32
                    r'train_loss[\s:=]\s*([\d.]+(?:e[+-]?\d+)?)',     # train_loss: 4.32
                    r'Loss[\s:=]\s*([\d.]+(?:e[+-]?\d+)?)',          # Loss: 4.32
                    r'è®­ç»ƒæŸå¤±[\s:=]\s*([\d.]+(?:e[+-]?\d+)?)',        # è®­ç»ƒæŸå¤±: 4.32
                    r'æŸå¤±[\s:=]\s*([\d.]+(?:e[+-]?\d+)?)',           # æŸå¤±: 4.32
                    r'\s+([\d.]+(?:e[+-]?\d+)?)\s*loss',             # 4.32 loss
                    r'\s+([\d.]+(?:e[+-]?\d+)?)\s*è®­ç»ƒæŸå¤±',         # 4.32 è®­ç»ƒæŸå¤±
                    r'(?:loss|æŸå¤±|training_loss|train_loss)\s*=\s*([\d.]+(?:e[+-]?\d+)?)'  # loss = 4.32
                ]
                
                for pattern in loss_patterns:
                    matches = re.findall(pattern, line, re.IGNORECASE)
                    if matches:
                        # å–æœ€åä¸€ä¸ªåŒ¹é…çš„losså€¼
                        loss_value = float(matches[-1])
                        if 0 < loss_value < 100:  # åˆç†çš„lossèŒƒå›´
                            current_loss = loss_value
                            break
            
            # æå–å­¦ä¹ ç‡ä¿¡æ¯ - æ”¯æŒå¤šç§æ ¼å¼
            if not current_lr:
                # æ ¼å¼: lr: 1e-4, learning_rate: 1e-4, LR: 1e-4, å­¦ä¹ ç‡: 1e-4
                lr_patterns = [
                    r'lr[\s:=]\s*([\d.e+-]+)',
                    r'learning_rate[\s:=]\s*([\d.e+-]+)',
                    r'LR[\s:=]\s*([\d.e+-]+)',
                    r'å­¦ä¹ ç‡[\s:=]\s*([\d.e+-]+)'
                ]
                
                for pattern in lr_patterns:
                    matches = re.findall(pattern, line, re.IGNORECASE)
                    if matches:
                        # å–æœ€åä¸€ä¸ªåŒ¹é…çš„lrå€¼
                        lr_value = float(matches[-1])
                        if 0 < lr_value < 1:  # åˆç†çš„lrèŒƒå›´
                            current_lr = f"{lr_value:.2e}"
                            break
            
            # å¦‚æœå·²ç»æ”¶é›†åˆ°è¶³å¤Ÿä¿¡æ¯ï¼Œæå‰é€€å‡º
            if total_epochs and current_loss and current_lr:
                break
        
        # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
        percentage = 0
        if total_epochs > 0:
            percentage = min(100, max(0, int((current_epoch / total_epochs) * 100)))
        
        # ä¼°ç®—å‰©ä½™æ—¶é—´ï¼ˆå¢å¼ºè®¡ç®—ï¼‰
        remaining_time = 'è®¡ç®—ä¸­...'
        if current_epoch > 0 and total_epochs > current_epoch:
            # ä»æ—¥å¿—ä¸­æå–æ—¶é—´ä¿¡æ¯
            for line in reversed(lines):
                # æ ¼å¼: remaining: 1:30:45, ETA: 1:30:45, é¢„è®¡å‰©ä½™: 1å°æ—¶30åˆ†é’Ÿ
                time_patterns = [
                    r'remaining[\s:=]\s*(\d+):(\d+):(\d+)',      # remaining: 1:30:45
                    r'ETA[\s:=]\s*(\d+):(\d+):(\d+)',            # ETA: 1:30:45
                    r'é¢„è®¡å‰©ä½™[\s:=]\s*(\d+)[\så°æ—¶]*[\s:]?(\d+)?[\såˆ†é’Ÿ]*',  # é¢„è®¡å‰©ä½™: 1å°æ—¶30åˆ†é’Ÿ
                    r'å‰©ä½™æ—¶é—´[\s:=]\s*(\d+)[\så°æ—¶]*[\s:]?(\d+)?[\såˆ†é’Ÿ]*',  # å‰©ä½™æ—¶é—´: 1å°æ—¶30åˆ†é’Ÿ
                    r'time left[\s:=]\s*(\d+)[\s:]?(\d+)?[\s:]?(\d+)?',  # time left: 1:30:45
                    r'è¿˜éœ€[\s:=]\s*(\d+)[\så°æ—¶]*[\s:]?(\d+)?[\såˆ†é’Ÿ]*'  # è¿˜éœ€: 1å°æ—¶30åˆ†é’Ÿ
                ]
                
                for pattern in time_patterns:
                    match = re.search(pattern, line, re.IGNORECASE)
                    if match:
                        groups = match.groups()
                        if len(groups) >= 3 and all(groups[:3]):
                            # å°æ—¶:åˆ†é’Ÿ:ç§’æ ¼å¼
                            hours = int(groups[0])
                            minutes = int(groups[1])
                            seconds = int(groups[2])
                            if hours > 0 or minutes > 0 or seconds > 0:
                                parts = []
                                if hours > 0: parts.append(f"{hours}å°æ—¶")
                                if minutes > 0: parts.append(f"{minutes}åˆ†é’Ÿ")
                                if seconds > 0 and hours == 0 and minutes == 0:
                                    parts.append(f"{seconds}ç§’")
                                remaining_time = ''.join(parts)
                                break
                        elif len(groups) >= 2:
                            # å°æ—¶å’Œåˆ†é’Ÿæ ¼å¼
                            hours = int(groups[0])
                            minutes = int(groups[1]) if groups[1] else 0
                            if hours > 0 or minutes > 0:
                                parts = []
                                if hours > 0: parts.append(f"{hours}å°æ—¶")
                                if minutes > 0: parts.append(f"{minutes}åˆ†é’Ÿ")
                                remaining_time = ''.join(parts)
                                break
                
                if remaining_time != 'è®¡ç®—ä¸­...':
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¶é—´ä¿¡æ¯ï¼Œæ ¹æ®è¿›åº¦ä¼°ç®—
            if remaining_time == 'è®¡ç®—ä¸­...':
                # å‡è®¾æ¯epochæ—¶é—´å¤§è‡´ç›¸åŒ
                elapsed_time = time.time() - process_info.get('start_timestamp', time.time())
                if current_epoch > 0:
                    time_per_epoch = elapsed_time / current_epoch
                    remaining_epochs = total_epochs - current_epoch
                    remaining_seconds = remaining_epochs * time_per_epoch
                    
                    if remaining_seconds > 3600:
                        remaining_time = f"{remaining_seconds / 3600:.1f}å°æ—¶"
                    elif remaining_seconds > 60:
                        remaining_time = f"{remaining_seconds / 60:.1f}åˆ†é’Ÿ"
                    else:
                        remaining_time = f"{int(remaining_seconds)}ç§’"
        
        return {
            'percentage': percentage,
            'current_epoch': current_epoch,
            'total_epochs': total_epochs,
            'remaining_time': remaining_time,
            'current_loss': f"{current_loss:.4f}" if current_loss else None,
            'current_lr': current_lr
        }
        
    except Exception as e:
        print(f"è®¡ç®—è¿›åº¦æ—¶å‡ºé”™: {e}")
        return progress

# è®­ç»ƒæ–¹å¼æ”¯æŒæ£€æµ‹
def get_supported_training_methods():
    """è·å–å½“å‰ç¯å¢ƒæ”¯æŒçš„è®­ç»ƒæ–¹æ³•"""
    methods = {
        'pretrain': True,  # é¢„è®­ç»ƒæ€»æ˜¯æ”¯æŒ
        'sft': True,       # SFTæ€»æ˜¯æ”¯æŒ
        'lora': True,      # LoRAæ€»æ˜¯æ”¯æŒ
        'dpo': True,       # DPOæ€»æ˜¯æ”¯æŒ
        'multi_gpu': HAS_TORCH and GPU_COUNT > 1  # å¤šGPUè®­ç»ƒéœ€è¦PyTorchå’Œå¤šä¸ªGPU
    }
    return methods

# è·å–å½“å‰ç¯å¢ƒæ”¯æŒçš„è®­ç»ƒæ–¹æ³•
SUPPORTED_METHODS = get_supported_training_methods()

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

app = Flask(__name__, template_folder='templates', static_folder='static')

# å­˜å‚¨è®­ç»ƒè¿›ç¨‹çš„ä¿¡æ¯
training_processes = {}

# è¿›ç¨‹ä¿¡æ¯æŒä¹…åŒ–æ–‡ä»¶
PROCESSES_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'training_processes.json')

# PIDæ–‡ä»¶
PID_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'train_web_ui.pid')

# Authentication removed - allow anonymous training

# å¯åŠ¨è®­ç»ƒè¿›ç¨‹
def start_training_process(train_type, params, client_id=None):
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # ä½¿ç”¨è¯¦ç»†çš„æ—¶é—´æˆ³ä½œä¸ºè¿›ç¨‹IDå’Œæ—¥å¿—æ–‡ä»¶å
    process_id = time.strftime('%Y%m%d_%H%M%S')
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    log_file = os.path.join(log_dir, f"train_{train_type}_{process_id}.log")
    
    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(log_dir, exist_ok=True)
    
    # è·å–GPUæ•°é‡å‚æ•°ï¼Œå¦‚æœå­˜åœ¨ä¸”å¤§äº1ï¼Œåˆ™ä½¿ç”¨torchrunå¯åŠ¨å¤šå¡è®­ç»ƒ
    gpu_num = int(params.get('gpu_num', 0)) if 'gpu_num' in params else 0
    use_torchrun = HAS_TORCH and GPU_COUNT > 0 and gpu_num > 1
    
    try:
        from .dispatcher import build_command
    except ImportError:
        import sys as _sys
        import os as _os
        _sys.path.append(_os.path.dirname(_os.path.abspath(__file__)))
        from dispatcher import build_command
    cmd = build_command(train_type, params, gpu_num, use_torchrun)
    if cmd is None:
        return None
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    with open(log_file, 'w') as f:
        f.write(f"å¼€å§‹è®­ç»ƒ {train_type} è¿›ç¨‹\n")
        f.write(f"å‘½ä»¤: {' '.join(cmd)}\n\n")
    
    # å¯åŠ¨è¿›ç¨‹
    process = subprocess.Popen(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        cwd=os.path.dirname(os.path.abspath(__file__))
    )
    
    # å­˜å‚¨è¿›ç¨‹ä¿¡æ¯
    training_processes[process_id] = {
        'process': process,
        'train_type': train_type,
        'log_file': log_file,
        'start_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'start_timestamp': time.time(),  # æ·»åŠ æ—¶é—´æˆ³ç”¨äºè¿›åº¦è®¡ç®—
        'running': True,
        'error': False,
        'train_monitor': params.get('train_monitor', 'none'),  # ä¿å­˜è®­ç»ƒç›‘æ§è®¾ç½®
        'swanlab_url': None,
        'next_line_is_swanlab_url': False,
        'client_id': client_id
    }
    
    # å¼€å§‹è¯»å–è¾“å‡º
    def read_output():
        try:
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯swanlabé“¾æ¥çš„è¡Œ
                    output_stripped = output.strip()
                    if training_processes[process_id]['next_line_is_swanlab_url']:
                        # ä¿å­˜swanlabé“¾æ¥
                        training_processes[process_id]['swanlab_url'] = output_stripped
                        training_processes[process_id]['next_line_is_swanlab_url'] = False
                    elif 'swanlab: ğŸš€ View run at' in output_stripped:
                        # æ ‡è®°ä¸‹ä¸€è¡Œæ˜¯swanlabé“¾æ¥
                        training_processes[process_id]['next_line_is_swanlab_url'] = True
                    
                    with open(log_file, 'a') as f:
                        f.write(output)
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦æˆåŠŸç»“æŸ
            if process.returncode != 0:
                training_processes[process_id]['error'] = True
        finally:
            training_processes[process_id]['running'] = False
    
    # å¯åŠ¨çº¿ç¨‹è¯»å–è¾“å‡º
    threading.Thread(target=read_output, daemon=True).start()
    
    return process_id

# Flaskè·¯ç”±
@app.route('/')
def index():
    # ä¼ é€’GPUä¿¡æ¯åˆ°å‰ç«¯
    return render_template('index.html', has_gpu=HAS_TORCH and GPU_COUNT > 0, gpu_count=GPU_COUNT)

@app.route('/healthz')
def healthz():
    try:
        return jsonify({'status': 'ok', 'gpu': GPU_COUNT, 'methods': SUPPORTED_METHODS}), 200
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/train', methods=['POST'])
def train():
    data = request.json
    train_type = data.get('train_type')
    
    # ç§»é™¤ä¸ç›¸å…³çš„å‚æ•°
    params = data.copy()
    
    # å¤„ç†å¤é€‰æ¡†å‚æ•°
    if 'from_resume' not in params:
        params['from_resume'] = '0'
    
    # å¯åŠ¨è®­ç»ƒè¿›ç¨‹ - å…è®¸åŒ¿åè®­ç»ƒï¼Œä¸ä¼ å…¥client_id
    process_id = start_training_process(train_type, params)
    
    if process_id:
        return jsonify({'success': True, 'process_id': process_id})
    else:
        return jsonify({'success': False, 'error': 'æ— æ•ˆçš„è®­ç»ƒç±»å‹'})

# æµ‹è¯•ç«¯ç‚¹ - æ·»åŠ æ¨¡æ‹Ÿè®­ç»ƒè¿›ç¨‹
@app.route('/test/add_process', methods=['POST'])
def add_test_process():
    """æ·»åŠ ä¸€ä¸ªæµ‹è¯•è¿›ç¨‹ç”¨äºéªŒè¯è‡ªåŠ¨æ›´æ–°åŠŸèƒ½"""
    import subprocess
    import threading
    
    process_id = f"test_process_{int(time.time())}"
    
    # åˆ›å»ºæµ‹è¯•è®­ç»ƒå‘½ä»¤
    test_command = [
        'python', '-c', '''
import time
import sys

print("2024-11-21 14:30:00 - Starting pretrain training")
sys.stdout.flush()
time.sleep(1)

print("2024-11-21 14:30:01 - Loading dataset from ../dataset/pretrain_hq.jsonl")
sys.stdout.flush()
time.sleep(1)

print("2024-11-21 14:30:02 - Model initialized with 108M parameters")
sys.stdout.flush()
time.sleep(2)

for epoch in range(1, 6):
    print(f"2024-11-21 14:30:{5 + epoch*5} - Starting epoch {epoch}/5")
    sys.stdout.flush()
    time.sleep(1)
    
    loss = 4.5 - epoch * 0.3
    lr = 1e-4 * (0.9 ** epoch)
    print(f"2024-11-21 14:30:{6 + epoch*5} - Loss: {loss:.4f}, lr: {lr:.2e}")
    sys.stdout.flush()
    time.sleep(2)
    
    remaining = (5 - epoch) * 15
    print(f"2024-11-21 14:30:{8 + epoch*5} - Epoch {epoch}/5 completed, remaining: 0:0{remaining}:00")
    sys.stdout.flush()
    time.sleep(1)

print("2024-11-21 14:30:35 - Training completed successfully")
sys.stdout.flush()
        '''
    ]
    
    # å¯åŠ¨è¿›ç¨‹
    process = subprocess.Popen(
        test_command,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        universal_newlines=True,
        bufsize=1
    )
    
    # ä¿å­˜è¿›ç¨‹ä¿¡æ¯
    log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '../logfile')
    log_dir = os.path.abspath(log_dir)
    os.makedirs(log_dir, exist_ok=True)
    
    training_processes[process_id] = {
        'process': process,
        'train_type': 'pretrain',
        'log_file': os.path.join(log_dir, f'{process_id}.log'),
        'start_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'start_timestamp': time.time(),
        'running': True,
        'error': False,
        'train_monitor': 'none',
        'swanlab_url': None
    }
    
    # å¯åŠ¨çº¿ç¨‹è¯»å–è¾“å‡ºå¹¶å†™å…¥æ—¥å¿—æ–‡ä»¶
    def read_output():
        try:
            log_file = training_processes[process_id]['log_file']
            with open(log_file, 'w') as f:
                for line in iter(process.stdout.readline, ''):
                    if line:
                        f.write(line)
                        f.flush()
            process.wait()
            training_processes[process_id]['running'] = False
            if process.returncode != 0:
                training_processes[process_id]['error'] = True
        except Exception as e:
            print(f"è¯»å–æµ‹è¯•è¿›ç¨‹è¾“å‡ºæ—¶å‡ºé”™: {e}")
            training_processes[process_id]['running'] = False
            training_processes[process_id]['error'] = True
    
    threading.Thread(target=read_output, daemon=True).start()
    
    return jsonify({
        'success': True,
        'process_id': process_id,
        'message': 'æµ‹è¯•è¿›ç¨‹å·²æ·»åŠ '
    })

@app.route('/processes')
def processes():
    result = []
    for process_id, info in training_processes.items():
        # ç¡®å®šçŠ¶æ€
        status = 'è¿è¡Œä¸­' if info['running'] else \
                'æ‰‹åŠ¨åœæ­¢' if 'manually_stopped' in info and info['manually_stopped'] else \
                'å‡ºé”™' if info['error'] else 'å·²å®Œæˆ'
        
        # è®¡ç®—è®­ç»ƒè¿›åº¦ä¿¡æ¯
        progress = calculate_training_progress(process_id, info)
                
        result.append({
            'id': process_id,
            'train_type': info['train_type'],
            'start_time': info['start_time'],
            'running': info['running'],
            'error': info['error'],
            'status': status,
            'train_monitor': info.get('train_monitor', 'none'),  # æ·»åŠ train_monitorå­—æ®µ
            'swanlab_url': info.get('swanlab_url'),  # æ·»åŠ swanlab_urlå­—æ®µ
            'progress': progress  # æ·»åŠ è¿›åº¦ä¿¡æ¯
        })
    return jsonify(result)

@app.route('/api/browse')
def browse_files():
    """
    æµè§ˆæœåŠ¡å™¨æ–‡ä»¶ç³»ç»Ÿ
    æ”¯æŒè¿œç¨‹æ–‡ä»¶é€‰æ‹©åŠŸèƒ½
    """
    try:
        # è·å–è¯·æ±‚çš„è·¯å¾„å‚æ•°
        path = request.args.get('path', './')
        
        # å®‰å…¨æ£€æŸ¥ï¼šé™åˆ¶è®¿é—®èŒƒå›´
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.abspath(os.path.join(script_dir, '..'))
        
        # è§£æè¯·æ±‚çš„è·¯å¾„
        if path.startswith('./'):
            # ç›¸å¯¹è·¯å¾„ï¼ŒåŸºäºé¡¹ç›®æ ¹ç›®å½•
            full_path = os.path.abspath(os.path.join(project_root, path[2:]))
        elif path.startswith('/'):
            # ç»å¯¹è·¯å¾„ï¼Œæ£€æŸ¥æ˜¯å¦åœ¨é¡¹ç›®ç›®å½•å†…
            full_path = os.path.abspath(path)
        else:
            # ç›¸å¯¹è·¯å¾„ï¼ŒåŸºäºé¡¹ç›®æ ¹ç›®å½•
            full_path = os.path.abspath(os.path.join(project_root, path))
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è·¯å¾„åœ¨é¡¹ç›®ç›®å½•å†…
        if not full_path.startswith(project_root):
            full_path = project_root
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(full_path):
            return jsonify({'error': 'è·¯å¾„ä¸å­˜åœ¨', 'path': path})
        
        # è·å–ç›®å½•å†…å®¹
        if os.path.isdir(full_path):
            items = []
            try:
                # åˆ—å‡ºç›®å½•å†…å®¹
                for item in sorted(os.listdir(full_path)):
                    item_path = os.path.join(full_path, item)
                    
                    # è·³è¿‡éšè—æ–‡ä»¶å’Œç³»ç»Ÿæ–‡ä»¶
                    if item.startswith('.') or item.startswith('__'):
                        continue
                    
                    try:
                        stat = os.stat(item_path)
                        items.append({
                            'name': item,
                            'path': item_path,  # è¿”å›ç»å¯¹è·¯å¾„
                            'relative_path': os.path.relpath(item_path, project_root),  # åŒæ—¶è¿”å›ç›¸å¯¹è·¯å¾„ç”¨äºæ˜¾ç¤º
                            'type': 'directory' if os.path.isdir(item_path) else 'file',
                            'size': stat.st_size if os.path.isfile(item_path) else 0,
                            'modified': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(stat.st_mtime))
                        })
                    except (OSError, PermissionError):
                        # è·³è¿‡æ— æ³•è®¿é—®çš„é¡¹ç›®
                        continue
                
                return jsonify({
                    'current_path': full_path,  # è¿”å›ç»å¯¹è·¯å¾„
                    'relative_path': os.path.relpath(full_path, project_root),  # ç›¸å¯¹è·¯å¾„ç”¨äºæ˜¾ç¤º
                    'absolute_path': full_path,
                    'items': items,
                    'parent': os.path.dirname(full_path) if full_path != project_root else None
                })
            except (OSError, PermissionError) as e:
                return jsonify({'error': f'æ— æ³•è®¿é—®ç›®å½•: {str(e)}', 'path': path})
        
        else:
            # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶ä¿¡æ¯
            stat = os.stat(full_path)
            return jsonify({
                'name': os.path.basename(full_path),
                'path': full_path,  # è¿”å›ç»å¯¹è·¯å¾„
                'relative_path': os.path.relpath(full_path, project_root),  # ç›¸å¯¹è·¯å¾„ç”¨äºæ˜¾ç¤º
                'type': 'file',
                'size': stat.st_size,
                'modified': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(stat.st_mtime))
            })
            
    except Exception as e:
        return jsonify({'error': f'æµè§ˆæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}'})

@app.route('/api/quick-paths')
def quick_paths():
    """
    è¿”å›å¸¸ç”¨è·¯å¾„å¿«æ·æ–¹å¼
    """
    try:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.abspath(os.path.join(script_dir, '..'))
        
        quick_paths = [
            {'name': 'é¡¹ç›®æ ¹ç›®å½•', 'path': './', 'type': 'directory'},
            {'name': 'æ•°æ®é›†ç›®å½•', 'path': './dataset', 'type': 'directory'},
            {'name': 'æ¨¡å‹æ£€æŸ¥ç‚¹', 'path': './checkpoints', 'type': 'directory'},
            {'name': 'æ—¥å¿—æ–‡ä»¶', 'path': './logfile', 'type': 'directory'}
        ]
        
        # éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨
        valid_paths = []
        for item in quick_paths:
            full_path = os.path.join(project_root, item['path'][2:] if item['path'].startswith('./') else item['path'])
            if os.path.exists(full_path):
                valid_paths.append(item)
        
        return jsonify({'paths': valid_paths})
        
    except Exception as e:
        return jsonify({'error': f'è·å–å¿«æ·è·¯å¾„æ—¶å‡ºé”™: {str(e)}'})

@app.route('/logs/<process_id>')
def logs(process_id):
    # ç›´æ¥ä»æœ¬åœ°logfileç›®å½•è¯»å–æ—¥å¿—æ–‡ä»¶
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    
    # æŸ¥æ‰¾åŒ¹é…çš„æ—¥å¿—æ–‡ä»¶
    log_file = None
    if os.path.exists(log_dir):
        for filename in os.listdir(log_dir):
            if filename.endswith(f'{process_id}.log'):
                log_file = os.path.join(log_dir, filename)
                break
    
    if not log_file or not os.path.exists(log_file):
        return 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤'
    
    try:
        # ä½¿ç”¨é«˜æ•ˆä¸”å¥å£®çš„æ–¹æ³•è¯»å–æ–‡ä»¶çš„æœ€å200è¡Œ
        def read_last_n_lines(file_path, n=200):
            # ä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼è¯»å–æ–‡ä»¶ï¼Œé¿å…ç¼–ç é—®é¢˜
            with open(file_path, 'rb') as f:
                # è·å–æ–‡ä»¶å¤§å°
                f.seek(0, os.SEEK_END)
                file_size = f.tell()
                
                # å¦‚æœæ–‡ä»¶å¾ˆå°ï¼Œç›´æ¥è¯»å–æ•´ä¸ªæ–‡ä»¶
                if file_size < 1024 * 1024:  # å°äº1MBçš„æ–‡ä»¶ç›´æ¥è¯»å–
                    f.seek(0)
                    content = f.read()
                    return process_content(content)
                
                # å¯¹äºå¤§æ–‡ä»¶ï¼Œä½¿ç”¨ç¼“å†²è¯»å–æœ«å°¾éƒ¨åˆ†
                # ä¼°è®¡éœ€è¦è¯»å–çš„å­—èŠ‚æ•°ï¼ˆå‡è®¾æ¯è¡Œå¹³å‡100å­—èŠ‚ï¼‰
                buffer_size = n * 200  # ä¸ºäº†ä¿é™©ï¼Œè¯»å–æ›´å¤šå­—èŠ‚
                
                # å®šä½åˆ°é€‚å½“çš„ä½ç½®
                position = max(0, file_size - buffer_size)
                f.seek(position)
                
                # è¯»å–ç¼“å†²åŒºå†…å®¹
                buffer = f.read(file_size - position)
                
                # å¤„ç†ç¼“å†²åŒºå†…å®¹
                lines = process_content(buffer)
                
                # ç¡®ä¿æˆ‘ä»¬è·å–åˆ°å®Œæ•´çš„è¡Œ
                # å¦‚æœç¼“å†²åŒºä¸æ˜¯ä»æ–‡ä»¶å¼€å¤´å¼€å§‹ï¼Œç¬¬ä¸€ä¸ªè¡Œå¯èƒ½ä¸å®Œæ•´
                if position > 0:
                    # è·³è¿‡ç¬¬ä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´çš„è¡Œ
                    if len(lines) > 1:
                        lines = lines[1:]
                    else:
                        # å¦‚æœåªæœ‰ä¸€è¡Œä¸”ä¸åœ¨æ–‡ä»¶å¼€å¤´ï¼Œå¯èƒ½éœ€è¦è¯»å–æ›´å¤š
                        # è¿™é‡Œç®€å•å¤„ç†ï¼Œç›´æ¥è¯»å–æ•´ä¸ªæ–‡ä»¶ï¼ˆç½•è§æƒ…å†µï¼‰
                        f.seek(0)
                        content = f.read()
                        lines = process_content(content)
                
                # è¿”å›æœ€ånè¡Œ
                return lines[-n:] if len(lines) > n else lines
        
        def process_content(content):
            # å°è¯•å¤šç§ç¼–ç æ–¹å¼è§£ç å†…å®¹
            encodings = ['utf-8', 'latin-1', 'gbk', 'gb2312']
            for encoding in encodings:
                try:
                    text = content.decode(encoding)
                    # ä½¿ç”¨Trueå‚æ•°ä¿ç•™æ¢è¡Œç¬¦ï¼Œç¡®ä¿è¡Œåˆ†éš”ç¬¦æ­£ç¡®
                    return text.splitlines(True)
                except UnicodeDecodeError:
                    continue
            # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨é”™è¯¯æ›¿æ¢æ¨¡å¼
            text = content.decode('utf-8', errors='replace')
            return text.splitlines(True)
        
        # è¯»å–æœ€å200è¡Œ
        last_200_lines = read_last_n_lines(log_file, 200)
        
        # ç¡®ä¿è¿”å›çš„å†…å®¹é¡ºåºæ­£ç¡®ï¼Œå¹¶ä¸”ä¸åŒ…å«ç©ºè¡Œ
        return ''.join(last_200_lines)
    except Exception as e:
        return f'è¯»å–æ—¥å¿—å¤±è´¥: {str(e)}'

@app.route('/logfiles')
def get_logfiles():
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    
    logfiles = []
    # è·å–æ‰€æœ‰è¿›ç¨‹IDç”¨äºå…³è”
    process_pids = set(training_processes.keys())
    
    if os.path.exists(log_dir):
        for filename in os.listdir(log_dir):
            if filename.endswith('.log') and filename.startswith('train_'):
                file_path = os.path.join(log_dir, filename)
                try:
                    modified_time = os.path.getmtime(file_path)
                    formatted_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(modified_time))
                    # æå–è¿›ç¨‹ID
                    pid = filename.split('.')[-2].split('_')[-1] if filename.endswith('.log') else None
                    logfiles.append({
                        'filename': filename,
                        'modified_time': formatted_time,
                        'size': os.path.getsize(file_path),
                        'process_id': pid,
                        'has_process': pid in process_pids
                    })
                except Exception as e:
                    continue
    # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
    logfiles.sort(key=lambda x: x['modified_time'], reverse=True)
    return jsonify(logfiles)

@app.route('/logfile-content/<filename>')
def get_logfile_content(filename):
    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åä¸åŒ…å«è·¯å¾„éå†å­—ç¬¦
    if '..' in filename or '/' in filename or '\\' in filename:
        return jsonify({'error': 'Invalid filename'}), 400
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œtrain_web_ui.pyåœ¨scriptsç›®å½•ä¸‹
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    log_file = os.path.join(log_dir, filename)
    
    try:
        # ä½¿ç”¨äºŒè¿›åˆ¶æ¨¡å¼è¯»å–æ–‡ä»¶ï¼Œå¯ä»¥æ›´å¯é åœ°ä¿ç•™åŸå§‹æ¢è¡Œç¬¦
        with open(log_file, 'rb') as f:
            content_bytes = f.read()
        
        # å°è¯•å¤šç§ç¼–ç æ–¹å¼è§£ç ï¼Œç¡®ä¿æ­£ç¡®å¤„ç†æ¢è¡Œç¬¦
        encodings = ['utf-8', 'latin-1', 'gbk', 'gb2312']
        content = None
        
        for encoding in encodings:
            try:
                # è§£ç æ–‡ä»¶å†…å®¹ï¼Œä¿ç•™åŸå§‹æ¢è¡Œç¬¦
                content = content_bytes.decode(encoding)
                break
            except UnicodeDecodeError:
                continue
        
        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä½¿ç”¨errors='replace'å‚æ•°å¤„ç†ä¸å¯è§£ç çš„å­—ç¬¦
        if content is None:
            content = content_bytes.decode('utf-8', errors='replace')
        
        # ç¡®ä¿è¿”å›çš„å†…å®¹æ­£ç¡®ä¿ç•™æ‰€æœ‰æ¢è¡Œç¬¦
        return content
    except FileNotFoundError:
        return jsonify({'error': 'Log file not found'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/delete-logfile/<filename>', methods=['DELETE'])
def delete_logfile(filename):
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»ºlogfileç›®å½•çš„ç»å¯¹è·¯å¾„
    log_dir = os.path.join(script_dir, '../logfile')
    log_dir = os.path.abspath(log_dir)
    
    # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
    if '..' in filename or '/' in filename or '\\' in filename:
        return jsonify({'success': False, 'message': 'éæ³•çš„æ–‡ä»¶å'})
    
    log_file = os.path.join(log_dir, filename)
    if os.path.exists(log_file) and os.path.isfile(log_file):
        try:
            os.remove(log_file)
            return jsonify({'success': True, 'message': 'æ—¥å¿—æ–‡ä»¶åˆ é™¤æˆåŠŸ'})
        except Exception as e:
            print(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
            return jsonify({'success': False, 'message': f'åˆ é™¤å¤±è´¥: {str(e)}'})
    return jsonify({'success': False, 'message': 'æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨'})


@app.route('/stop/<process_id>', methods=['POST'])
def stop(process_id):
    if process_id in training_processes and training_processes[process_id]['running']:
        process = training_processes[process_id]['process']
        # åœ¨Windowsä¸Šä½¿ç”¨terminateï¼Œåœ¨Unixä¸Šå°è¯•ä¼˜é›…ç»ˆæ­¢
        try:
            process.terminate()
            # ç­‰å¾…è¿›ç¨‹ç»“æŸ
            process.wait(timeout=5)
            # æ ‡è®°ä¸ºæ‰‹åŠ¨åœæ­¢
            training_processes[process_id]['running'] = False
            training_processes[process_id]['manually_stopped'] = True
        except subprocess.TimeoutExpired:
            # å¦‚æœè¶…æ—¶ï¼Œå¼ºåˆ¶æ€æ­»
            process.kill()
            # æ ‡è®°ä¸ºæ‰‹åŠ¨åœæ­¢
            training_processes[process_id]['running'] = False
            training_processes[process_id]['manually_stopped'] = True
        return jsonify({'success': True})
    return jsonify({'success': False})

@app.route('/delete/<process_id>', methods=['POST'])
def delete(process_id):
    if process_id in training_processes:
        # ç¡®ä¿è¿›ç¨‹å·²ç»åœæ­¢
        if training_processes[process_id]['running']:
            # å¦‚æœè¿›ç¨‹è¿˜åœ¨è¿è¡Œï¼Œå…ˆåœæ­¢å®ƒ
            try:
                process = training_processes[process_id]['process']
                process.terminate()
                try:
                    process.wait(timeout=3)
                except subprocess.TimeoutExpired:
                    process.kill()
            except Exception as e:
                print(f"åœæ­¢è¿›ç¨‹å¤±è´¥: {str(e)}")
        
        # ä»è¿›ç¨‹å­—å…¸ä¸­åˆ é™¤
        del training_processes[process_id]
        
        # å¯é€‰ï¼šåˆ é™¤å¯¹åº”çš„æ—¥å¿—æ–‡ä»¶
        try:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            log_dir = os.path.join(script_dir, '../logfile')
            log_dir = os.path.abspath(log_dir)
            
            if os.path.exists(log_dir):
                for filename in os.listdir(log_dir):
                    if filename.endswith(f'{process_id}.log'):
                        os.remove(os.path.join(log_dir, filename))
        except Exception as e:
            print(f"åˆ é™¤æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        return jsonify({'success': True})
    return jsonify({'success': False})

def find_available_port(start_port=12581, max_attempts=100):
    """æŸ¥æ‰¾å¯ç”¨çš„ç«¯å£å·
    
    Args:
        start_port: èµ·å§‹ç«¯å£å·
        max_attempts: æœ€å¤§å°è¯•æ¬¡æ•°
        
    Returns:
        å¯ç”¨çš„ç«¯å£å·ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
    """
    for port in range(start_port, start_port + max_attempts):
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        result = sock.connect_ex(('localhost', port))
        sock.close()
        if result != 0:  # ç«¯å£å¯ç”¨
            return port
    return None

def save_processes_info():
    """ä¿å­˜è®­ç»ƒè¿›ç¨‹ä¿¡æ¯åˆ°æ–‡ä»¶"""
    try:
        # åˆ›å»ºä¸€ä¸ªä¸åŒ…å«è¿›ç¨‹å¯¹è±¡çš„å¯åºåˆ—åŒ–ç‰ˆæœ¬
        serializable_processes = {}
        for pid, info in training_processes.items():
            serializable_processes[pid] = {
                'pid': info.get('pid', info.get('process').pid) if isinstance(info.get('process'), subprocess.Popen) else info.get('pid'),
                'train_type': info['train_type'],
                'log_file': info['log_file'],
                'start_time': info['start_time'],
                'running': info['running'],
                'error': info.get('error', False),
                'manually_stopped': info.get('manually_stopped', False),
                'train_monitor': info.get('train_monitor', 'none'),  # ä¿å­˜train_monitor
                'swanlab_url': info.get('swanlab_url'),
                'client_id': info.get('client_id')
            }
        
        with open(PROCESSES_FILE, 'w', encoding='utf-8') as f:
            json.dump(serializable_processes, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ä¿å­˜è¿›ç¨‹ä¿¡æ¯å¤±è´¥: {str(e)}")

def load_processes_info():
    """ä»æ–‡ä»¶åŠ è½½è®­ç»ƒè¿›ç¨‹ä¿¡æ¯"""
    global training_processes
    try:
        if os.path.exists(PROCESSES_FILE):
            with open(PROCESSES_FILE, 'r', encoding='utf-8') as f:
                loaded_processes = json.load(f)
            
            # æ£€æŸ¥æ¯ä¸ªè¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
            for pid, info in loaded_processes.items():
                # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„å­—æ®µéƒ½å­˜åœ¨
                if 'swanlab_url' not in info:
                    info['swanlab_url'] = None
                if 'manually_stopped' not in info:
                    info['manually_stopped'] = False
                if 'error' not in info:
                    info['error'] = False
                if 'train_monitor' not in info:
                    info['train_monitor'] = 'none'
                if 'client_id' not in info:
                    info['client_id'] = None
                
                if info['running']:
                    try:
                        # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
                        proc = psutil.Process(info['pid'])
                        if proc.is_running() and proc.status() != 'zombie':
                            # è¿›ç¨‹ä»åœ¨è¿è¡Œï¼Œæ¢å¤ä¿¡æ¯
                            training_processes[pid] = info
                        else:
                            # è¿›ç¨‹å·²åœæ­¢
                            info['running'] = False
                            # å¦‚æœè¿›ç¨‹æœªè¢«æ˜ç¡®æ ‡è®°ä¸ºå®Œæˆæˆ–å‡ºé”™ï¼Œåˆ™é»˜è®¤ä¸ºæ‰‹åŠ¨åœæ­¢
                            if not info['error']:
                                info['manually_stopped'] = True
                            training_processes[pid] = info
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        # è¿›ç¨‹ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®
                        info['running'] = False
                        # å¦‚æœè¿›ç¨‹æœªè¢«æ˜ç¡®æ ‡è®°ä¸ºå®Œæˆæˆ–å‡ºé”™ï¼Œåˆ™é»˜è®¤ä¸ºæ‰‹åŠ¨åœæ­¢
                        if not info['error']:
                            info['manually_stopped'] = True
                        training_processes[pid] = info
                else:
                    # è¿›ç¨‹å·²åœæ­¢ï¼Œç›´æ¥æ¢å¤
                    training_processes[pid] = info
    except Exception as e:
        print(f"åŠ è½½è¿›ç¨‹ä¿¡æ¯å¤±è´¥: {str(e)}")

def handle_exit(signum, frame):
    """å¤„ç†ç¨‹åºé€€å‡ºä¿¡å·ï¼Œä¿å­˜è¿›ç¨‹ä¿¡æ¯"""
    print("æ­£åœ¨ä¿å­˜è¿›ç¨‹ä¿¡æ¯...")
    save_processes_info()
    # åˆ é™¤PIDæ–‡ä»¶
    if os.path.exists(PID_FILE):
        try:
            os.remove(PID_FILE)
        except:
            pass
    sys.exit(0)

# æ³¨å†Œé€€å‡ºå¤„ç†å™¨
signal.signal(signal.SIGINT, handle_exit)  # Ctrl+C
if hasattr(signal, 'SIGTERM'):
    signal.signal(signal.SIGTERM, handle_exit)  # ç»ˆæ­¢ä¿¡å·

# æ³¨å†Œç¨‹åºé€€å‡ºæ—¶çš„å¤„ç†å‡½æ•°
atexit.register(save_processes_info)

if __name__ == '__main__':
    # åŠ è½½å·²ä¿å­˜çš„è¿›ç¨‹ä¿¡æ¯
    load_processes_info()
    
    # åˆ›å»ºPIDæ–‡ä»¶ï¼Œç”¨äºæ ‡è¯†webè¿›ç¨‹
    with open(PID_FILE, 'w') as f:
        f.write(str(os.getpid()))
    
    # å°è¯•ä½¿ç”¨é»˜è®¤ç«¯å£12581ï¼Œå¦‚æœè¢«å ç”¨åˆ™è‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£
    port = find_available_port(12581)
    if port is not None:
        print(f"å¯åŠ¨FlaskæœåŠ¡å™¨åœ¨ http://0.0.0.0:{port}")
        print(f"ä½¿ç”¨nohupå¯åŠ¨å¯ä¿æŒæœåŠ¡æŒç»­è¿è¡Œ: nohup python -u scripts/train_web_ui.py &")
        # ä½¿ç”¨0.0.0.0ä½œä¸ºhostä»¥å…¼å®¹VSCodeçš„ç«¯å£è½¬å‘åŠŸèƒ½
        app.run(host='0.0.0.0', port=port, debug=False)  # ç”Ÿäº§ç¯å¢ƒå…³é—­debug
    else:
        print("æ— æ³•æ‰¾åˆ°å¯ç”¨çš„ç«¯å£ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿç«¯å£å ç”¨æƒ…å†µ")
        # åˆ é™¤PIDæ–‡ä»¶
        if os.path.exists(PID_FILE):
            try:
                os.remove(PID_FILE)
            except:
                pass
        sys.exit(1)
# Registration endpoint removed - allow anonymous training